{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n",
      "0\n",
      "NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating tensors:\n",
    "X = torch.ones(size=(1000,1000)) # ones\n",
    "X = torch.zeros(size=(1000,1000)) # zeros\n",
    "X = torch.normal(0,1,size=(1000,1000)) # normal 0,1\n",
    "X = torch.rand(size=(1000,1000)) # random uniform[0,1]\n",
    "\n",
    "X = torch.from_numpy(np.random.normal(size=(1000,1000))) # from numpy\n",
    "X = X.numpy() # and back to numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Location: 140512254339168\n",
      "In place: True Location: 140512254339168\n",
      "In place: True Location: 140512254339168\n",
      "In place: False Location: 140512240050064\n"
     ]
    }
   ],
   "source": [
    "# memory usage: use X+= or X[:] to avoid unnecessary copying\n",
    "X, Y = torch.normal(0,1,size=(1000,1000)), torch.rand(size=(1000,1000)) \n",
    "original_id = id(X) \n",
    "print('Initial Location:', original_id) \n",
    "X += Y # in place\n",
    "print('In place:', id(X) == original_id, 'Location:', id(X))\n",
    "X[:] = X+Y # in place\n",
    "print('In place:', id(X) == original_id, 'Location:', id(X))\n",
    "X = X+Y # copy (uses more memory)\n",
    "print('In place:', id(X) == original_id, 'Location:', id(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Items in Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5410) torch.float32\n",
      "-0.54095966\n",
      "-0.5409596562385559 -0.5409596562385559\n"
     ]
    }
   ],
   "source": [
    "# accessing a single item:\n",
    "a = X[0,0] # returns a 1x1 tensor\n",
    "print(a, a.dtype) # show tensor and dtype\n",
    "print(a.numpy()) # numpy array\n",
    "print(a.item(), float(a)) # pythong floats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(999.6523)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linear Algebra\n",
    "\"\"\"\n",
    "\n",
    "X @ X.T # matrix multiplaction, transpose\n",
    "X.norm() # norm (frobenius i.e. l2)  c1000 = sqrt(1m) since we have 1m numbers normaly distributed N(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2lai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
